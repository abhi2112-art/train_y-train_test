# -*- coding: utf-8 -*-
"""Untitled18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nt1LjOdU-yhBUPltn6oE6xNMwQ7_nz5x
"""

import pandas as pd

import matplotlib.pyplot as plt
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

data=pd.read_sas("/content/bankloan.sas7bdat")

data

data.info()

df=data[~data["default"].isnull()]
df

def IQR(x):
    q1 = x.quantile(0.25)
    q3 = x.quantile(0.75)
    iqr = q3 - q1
    lf = q1 - (1.5*iqr)
    uf = q3+(1.5*iqr)
    print("LF",lf)
    print("UF",uf)

IQR(df["age"])

plt.boxplot(df["age"])
plt.show()

IQR(df["ed"])

plt.boxplot(df["age"])
plt.show()

IQR(df["employ"])

plt.boxplot(df["employ"])
plt.show()

df["employ"] = np.where(df["employ"]>25.5,25.5,df["employ"])

IQR(df["employ"])

IQR(df["address"])
plt.boxplot(df["address"])
plt.show()

df["address"] = np.where(df["address"]>25.5,25.5,df["address"])

IQR(df["income"])
plt.boxplot(df["income"])
plt.show()

df["income"] = np.where(df["income"]>101.5,101.5,df["income"])

IQR(df["debtinc"])
plt.boxplot(df["debtinc"])
plt.show()

df["debtinc"]=np.where(df["debtinc"]>27.812,27.812,df["debtinc"])

IQR(df["creddebt"])
plt.boxplot(df["creddebt"])
plt.show()

df["creddebt"] = np.where(df["creddebt"]>4.20,4.20,df["creddebt"])

IQR(df["othdebt"])
plt.boxplot(df["othdebt"])
plt.show()

df["othdebt"] = np.where(df["othdebt"]>8.2413945,8.2413945,df["othdebt"])

def outliers(x):
  y=x.select_dtypes(include=[int,float])

df.columns

X=df[['age', 'ed', 'employ', 'address', 'income', 'debtinc', 'creddebt',
       'othdebt']]
y=df["default"]

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,
                                                random_state=58)

log=LogisticRegression()

log.fit(X_train,y_train)

print("Train accuracy",log.score(X_train,y_train))
print("Train accuracy",log.score(X_test,y_test))

sample=data[data["default"].isnull()]
sample

sample.drop(columns="default",inplace=True)

from sklearn.metrics import classification_report

print(classification_report(y_train,log.predict(X_train)))
print("============================================")
print(classification_report(y_test,log.predict(X_test)))

#X_train probability
pro_train=pd.DataFrame(log.predict_proba(X_train),columns=["Pro_0","Pro_1"])
pro_train

copy=X_train.copy()

copy["pre_y"]=log.predict(copy)

copy["manual_y"]=np.where(pro_train["Pro_1"]>0.5,1,0)
copy

actual=y_train
pre_y=np.where(pro_train["Pro_1"]>0.3,1,0)
print(classification_report(actual,pre_y))

